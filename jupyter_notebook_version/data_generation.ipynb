{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "#from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameter\n",
    "ORIGINAL_PATH = \"HR_img\"\n",
    "STORE_PATH = \"LR_img_new\"\n",
    "DOWN_SCALE_FACTOR = 0.25\n",
    "\n",
    "\n",
    "\n",
    "def is_human_img(img,detector):\n",
    "    # detect whether there is a face in this image\n",
    "    faces = detector.detect_faces(img)\n",
    "    if(len(faces)!=0):\n",
    "        return True\n",
    "    print(\"no human in the image\")\n",
    "    return False\n",
    "\n",
    "def init_dir(store_path=STORE_PATH):\n",
    "    if not os.path.isdir(store_path):\n",
    "        os.mkdir(store_path)\n",
    "\n",
    "def two_K_human_img_selection(original_dir,store_dir,begin_idx,detect_human=False):\n",
    "    # select 2K images\n",
    "    init_dir(store_dir)\n",
    "    if detect_human:\n",
    "        detector = MTCNN()\n",
    "    files = [f for f in os.listdir(original_dir)]\n",
    "    for file in files:\n",
    "        path = original_dir + \"/\" + file # img path\n",
    "        img = cv2.imread(path)\n",
    "        height, width, channels = img.shape\n",
    "        if height > 2000 or width > 2000:\n",
    "            # check the img size\n",
    "            if detect_human:\n",
    "                if is_human_img(img,detector):\n",
    "                    store_path = store_dir + \"/\" + str(begin_idx) + \".jpg\"\n",
    "                    cv2.imwrite(store_path,img)\n",
    "                    begin_idx += 1\n",
    "            else:\n",
    "                store_path = store_dir + \"/\" + str(begin_idx) + \".jpg\"\n",
    "                cv2.imwrite(store_path, img)\n",
    "                begin_idx += 1\n",
    "\n",
    "def create_database(original_dir,store_dir,down_factor):\n",
    "    init_dir(store_dir)\n",
    "    size = len(os.listdir(original_dir))\n",
    "\n",
    "    for i in range(size):\n",
    "        path = original_dir + '/' + str(i) + '.jpg'\n",
    "        img = cv2.imread(path)\n",
    "        height, width, channels = img.shape\n",
    "        img = cv2.resize(img,(int(down_factor*width),int(down_factor*height)),interpolation= cv2.INTER_CUBIC)\n",
    "        store_path = store_dir + \"/\" + str(i) + \".jpg\"\n",
    "        cv2.imwrite(store_path,img)\n",
    "        if i%200 == 0: print('Processed Row image {} of {}'.format(i, size))\n",
    "    print('finish image generation')\n",
    "\n",
    "\n",
    "def crop_with_scale(original_dir,store_dir,size_factor):\n",
    "    # ensure the data is factors of size_factor\n",
    "    init_dir(store_dir)\n",
    "    #size = len(os.listdir(original_dir))\n",
    "    for name in os.listdir(original_dir):\n",
    "        path = original_dir + '/' + name\n",
    "        img = cv2.imread(path)\n",
    "        height, width, channels = img.shape\n",
    "        new_h = int(height/size_factor)*size_factor\n",
    "        new_w = int(width/size_factor)*size_factor\n",
    "        img = img[:new_h,:new_w,:]\n",
    "        store_path = store_dir + \"/\" + name\n",
    "        cv2.imwrite(store_path, img)\n",
    "\n",
    "\n",
    "def data_augment(img_dir,store_dir,flip=True,crop_aug=True):\n",
    "    # could add more augmentation\n",
    "    init_dir(store_dir)\n",
    "    imgs = os.listdir(img_dir)\n",
    "    for name in imgs:\n",
    "        img = cv2.imread(img_dir+'/'+name)\n",
    "        aug_imgs = []\n",
    "        aug_imgs.append(img)\n",
    "        # flip\n",
    "        if flip:\n",
    "            aug_imgs.append(np.fliplr(img))\n",
    "        # crop part of the image\n",
    "        if crop_aug:\n",
    "            height = img.shape[0]\n",
    "            width = img.shape[1]\n",
    "            crop_1 = img[:int(height*0.9),:int(width*0.9)]\n",
    "            crop_2 = img[int(height*0.1):,int(width*0.1):]\n",
    "            aug_imgs.append(crop_1)\n",
    "            aug_imgs.append(crop_2)\n",
    "            if flip:\n",
    "                # get flip img\n",
    "                flip_img = aug_imgs[1]\n",
    "                crop_3 = flip_img[:int(height * 0.9), :int(width * 0.9)]\n",
    "                crop_4 = flip_img[int(height * 0.1):, int(width * 0.1):]\n",
    "                aug_imgs.append(crop_3)\n",
    "                aug_imgs.append(crop_4)\n",
    "        # store aug_imgs\n",
    "        prefix = name.split('.')[0]\n",
    "        for i in range(len(aug_imgs)):\n",
    "            aug_img = aug_imgs[i]\n",
    "            store_path = store_dir + \"/\" + prefix + '_' + str(i) + \".jpg\"\n",
    "            cv2.imwrite(store_path,aug_img)\n",
    "\n",
    "\n",
    "def face_crop(img_dir,store_dir):\n",
    "    init_dir(store_dir)\n",
    "    detector = MTCNN()\n",
    "    imgs = os.listdir(img_dir)\n",
    "    for name in imgs:\n",
    "        img = cv2.imread(img_dir+'/'+name)\n",
    "        try:\n",
    "            faces = detector.detect_faces(img)\n",
    "        except:\n",
    "            print('do next face detection')\n",
    "            continue\n",
    "        print('detect img - ' + name)\n",
    "        print('detected len:',len(faces))\n",
    "        for i in range(len(faces)):\n",
    "            face = faces[i]\n",
    "            print(face)\n",
    "            box = face['box']\n",
    "            confidence = face['confidence']\n",
    "            if confidence < 0.95:\n",
    "                # threshold to get just high confidence image\n",
    "                continue\n",
    "            skip = False\n",
    "            for par in box:\n",
    "                # box is out of range\n",
    "                if par < 0 :\n",
    "                    skip = True\n",
    "            if skip:\n",
    "                continue\n",
    "            crop_img = img[box[1]:box[1]+box[3],box[0]:box[0]+box[2]]\n",
    "            prefix = name.split('.')[0]\n",
    "            store_path = store_dir + \"/\" + prefix + '_' + str(i) + \".jpg\"\n",
    "            cv2.imwrite(store_path, crop_img)\n",
    "\n",
    "def img_transform(img_dir,store_dir,size_factor,transform = 'bicubic'):\n",
    "    # decrease the size of img by the factor and recover back using the transform method\n",
    "    init_dir(store_dir)\n",
    "    if transform == 'bicubic':\n",
    "        imgs = os.listdir(img_dir)\n",
    "        for name in imgs:\n",
    "            img = cv2.imread(img_dir + '/' + name)\n",
    "            width = int(img.shape[1] * size_factor)\n",
    "            height = int(img.shape[0] * size_factor)\n",
    "            dim = (width, height)\n",
    "            trans_img = cv2.resize(img,dim,interpolation=cv2.INTER_CUBIC)\n",
    "            store_path = store_dir + \"/\" + name\n",
    "            cv2.imwrite(store_path,trans_img)\n",
    "\n",
    "def add_noise(img_dir,store_dir,factor):\n",
    "    # add gaussian noise to image, with a factor.\n",
    "    init_dir(store_dir)\n",
    "    imgs = os.listdir(img_dir)\n",
    "    for name in imgs:\n",
    "        img = cv2.imread(img_dir + '/' + name)\n",
    "        trans_img = cv2.resize(img,dim,interpolation=cv2.INTER_CUBIC)\n",
    "        store_path = store_dir + \"/\" + name\n",
    "        cv2.imwrite(store_path,trans_img)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #two_K_human_img_selection(\"original_img\",\"input_img2\",0)\n",
    "    #crop_with_scale('face_img','face_img_4',4)\n",
    "    #create_database('HR_img_4','LR_img_0.25',0.25)\n",
    "    #face_crop('HR_img','face_img')\n",
    "    #data_augment('HR_img','HR_img_aug')\n",
    "    #crop_with_scale('HR_img_aug','HR_img_aug_4',4)\n",
    "    img_transform('.//face_img_4//','.//LR_face_img//',0.25)\n",
    "   # img_transform('.//BICUIBIC//changed//','.//BICUIBIC//up',4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
